{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Staging Upload to ImageCalc Table\n",
    "This notebook goes through an example of uploading a classified planet image, a logfile, and training data to the DSWx calval database. Data files and metadata are uploading to a staging bucket. Then, the database manager will commit these uploads to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import os\n",
    "from datetime import datetime\n",
    "import sys\n",
    "sys.path.insert(0, './tools/')\n",
    "from addImageCalc import addImageCalc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "editor_name = 'Alexander Handwerger'\n",
    "uploadDir = '/Users/mbonnema/Documents/OPERA_calval/DSWx/Chip_3_4/'\n",
    "site_name = '3_4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_image_filename = '3_4_classified_2class_ALH.tif'\n",
    "log_filename = 'Log notes.docx'\n",
    "#additional_filename = 'additional_file.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS Credentials\n",
    "In order to download imagery from the private bucket, JPL RSA access and OPERA Calval AWS credenitals are needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'opera-calval-database-dswx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.session.Session(profile_name='saml-pub')\n",
    "s3 = session.resource('s3')\n",
    "s3_client = session.client('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Image metadata table\n",
    "To get the geometry metadata for the classified image, we copy the geometry of the source image from the database since the extents are the same. This geometry could also be generated directly from the classified imagery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageTable = gpd.read_file(s3.Object(bucket_name,'image.geojson').get()['Body'])\n",
    "imagecalcTable = gpd.read_file(s3.Object(bucket_name,'image_calc.geojson').get()['Body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>collocated_dswx</th>\n",
       "      <th>datetime</th>\n",
       "      <th>image_name</th>\n",
       "      <th>instrument</th>\n",
       "      <th>provider</th>\n",
       "      <th>resolution</th>\n",
       "      <th>s3_bucket</th>\n",
       "      <th>s3_key_image</th>\n",
       "      <th>site_coverage</th>\n",
       "      <th>site_name</th>\n",
       "      <th>timeDelta_days</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.0</td>\n",
       "      <td>HLS.S30.T20HLJ.2021294T141049.v2.0</td>\n",
       "      <td>2021-10-21T13:30:31</td>\n",
       "      <td>20211021_133031_75_245a</td>\n",
       "      <td>PSB.SD</td>\n",
       "      <td>planetscope</td>\n",
       "      <td>3.0</td>\n",
       "      <td>opera-calval-database-dswx-private</td>\n",
       "      <td>data/3_4/20211021_133031_75_245a/20211021_1330...</td>\n",
       "      <td>97.954495</td>\n",
       "      <td>3_4</td>\n",
       "      <td>0.035727</td>\n",
       "      <td>POLYGON ((-64.30053 -33.07480, -64.34944 -33.2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cloud_cover                     collocated_dswx             datetime  \\\n",
       "132          0.0  HLS.S30.T20HLJ.2021294T141049.v2.0  2021-10-21T13:30:31   \n",
       "\n",
       "                  image_name instrument     provider  resolution  \\\n",
       "132  20211021_133031_75_245a     PSB.SD  planetscope         3.0   \n",
       "\n",
       "                              s3_bucket  \\\n",
       "132  opera-calval-database-dswx-private   \n",
       "\n",
       "                                          s3_key_image  site_coverage  \\\n",
       "132  data/3_4/20211021_133031_75_245a/20211021_1330...      97.954495   \n",
       "\n",
       "    site_name  timeDelta_days  \\\n",
       "132       3_4        0.035727   \n",
       "\n",
       "                                              geometry  \n",
       "132  POLYGON ((-64.30053 -33.07480, -64.34944 -33.2...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = imageTable[imageTable.site_name == '3_4']\n",
    "search.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "planet_image = search.iloc[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry = planet_image.geometry.iloc[0]\n",
    "now = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter the required file locations and metadata fields\n",
    "To upload the classified image, we need to specify its location on the local computer (and the location of auxilary files). We also need to fill in some metadata fields. Both file paths and metadata are specified as dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePaths = {\n",
    "    'image_calc' : uploadDir + classified_image_filename,\n",
    "    'logfile' : uploadDir + log_filename,\n",
    "    #additional_file: additional_file_name\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_name': '20211021_133031_75_245a',\n",
       " 'image_calc_name': '20211021_133031_75_245a_class',\n",
       " 'previous_name': None,\n",
       " 'calc_type': 'Supervised Classification',\n",
       " 'processing_level': 'Intermediate',\n",
       " 'oversight_level': None,\n",
       " 'calculated_by': 'Alexander Handwerger',\n",
       " 'reviewed_by': None,\n",
       " 'public': True,\n",
       " 'geometry': <shapely.geometry.polygon.Polygon at 0x7fd361bb2b10>}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metaData = {\n",
    "    'image_name':planet_image.image_name.iloc[0], #str\n",
    "    'image_calc_name':planet_image.image_name.iloc[0]+'_class', #str \n",
    "    'previous_name':None, #str\n",
    "    'calc_type':'Supervised Classification', #str\n",
    "    'processing_level':'Intermediate', #str\n",
    "    'oversight_level':None, #str,\n",
    "    'calculated_by': editor_name, #str\n",
    "    'reviewed_by': None, #str\n",
    "    'public':True, #bool\n",
    "    'geometry':geometry, #shapely geometry\n",
    "}\n",
    "metaData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage the image\n",
    "We use a pre-defined function to upload files and metadata to the staging area. This function takes the file paths and metadata dictionaries, as well as the AWS session object as inputs\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating geojson table\n",
      "Uploading geojson table\n",
      "Uploading files\n",
      "staging complete\n"
     ]
    }
   ],
   "source": [
    "addImageCalc(filePaths,metaData,session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
